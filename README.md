# DMZ LLM + RAG Sandbox

A self-contained, Docker-based environment simulating a **DMZ Large Language Model** with Retrieval-Augmented Generation (RAG) capabilities.  
Includes a lightweight dev machine, web-based desktop (Webtop), and a Streamlit UI for interaction.

---

## üì¶ Components

### **Backend**
- **Ollama** ‚Äî Runs the selected LLM model (default: `llama3`).
- **RAG API** ‚Äî FastAPI + ChromaDB backend for document ingestion and semantic search.
- **Vector Store** ‚Äî ChromaDB (embedded inside RAG API container) stores embeddings and metadata.

### **Frontend**
- **Streamlit UI** ‚Äî Web interface to:
  - Send prompts directly to the LLM.
  - Ingest text into the RAG knowledge base.
  - Query the RAG for context-aware answers.

### **Dev Environment**
- **Dev Machine** ‚Äî SSH-accessible Ubuntu container for testing tools in the same network.
- **Webtop** ‚Äî Browser-accessible Ubuntu desktop with a web browser, running fully in Docker.

---

## üóÇ Project Structure
```bash
project-root/
‚îú‚îÄ‚îÄ docker-compose.yml # Orchestrates all services
‚îú‚îÄ‚îÄ llm/ # Ollama build & init scripts
‚îú‚îÄ‚îÄ rag-api/ # RAG backend
‚îú‚îÄ‚îÄ frontend/ # Streamlit frontend
‚îú‚îÄ‚îÄ dev-machine/ # CLI dev environment
‚îî‚îÄ‚îÄ webtop-config/ # Webtop persistent storage
```
---

## üì¶ Services
- **ollama** ‚Äì LLM service for natural language processing.
- **rag-api** ‚Äì Backend for document ingestion & retrieval.
- **llm-ui** ‚Äì Streamlit web app for querying the LLM.
- **dev-machine** ‚Äì SSH-accessible terminal environment.
- **webtop** ‚Äì Lightweight remote Linux desktop with browser.

---
## üìä How RAG Works

```mermaid
flowchart TD
    A[User Input in UI] -->|Query or Document| B[RAG API]
    B -->|Embeds Text| C[ChromaDB Vector Store]
    C -->|Finds Relevant Context| D[Ollama LLM]
    D -->|Generates Response| A
```
---

## üöÄ Getting Started

### 1. Clone the repository
```bash
git clone https://github.com/war1u5/cydex_scenario
cd project-root
```
### 2. Build and start all services:
```bash
docker compose up --build -d
```
### 3. Access the services:
- **Frontend UI**: http://localhost:8501
- **Webtop (GUI)**: http://localhost:3000
- **SSH Dev Machine**: `ssh -p 2222 user@localhost`

## üìå Usage
- Use **/ingest** endpoint in RAG API to store documents.
- Use **/query** endpoint to retrieve context-aware answers.
- Directly interact with the LLM via the Streamlit UI.
- Develop inside `dev-machine` or use `webtop` for GUI tools.

## ‚ö†Ô∏è Notes
- Ensure Docker and Docker Compose are installed.
- Update `.env` or environment variables for custom configuration.
- The system is meant for local/offline usage; secure before exposing.